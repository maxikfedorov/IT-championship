# src/amp_generator/three_phase_generator.py

import pandas as pd
import asyncio
from dataclasses import dataclass
from typing import List, Dict
import os
import glob

@dataclass
class GeneratorConfig:
    frequency: float = 50.0
    sampling_rate: float = 25600.0
    amplitude: float = 3.0
    noise_level: float = 0.05
    anomaly_chance: float = 0.0
    phase_drop_chance: float = 0.0
    voltage_imbalance: float = 0.02
    output_batch_size: int = 1
    csv_files: List[str] = None  # üîß –ù–û–í–û–ï: —Å–ø–∏—Å–æ–∫ CSV —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏

class ThreePhaseGenerator:
    def __init__(self, config: GeneratorConfig = None):
        self.config = config or GeneratorConfig()
        
        # üîß –ù–û–í–û–ï: –ï—Å–ª–∏ —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –Ω–µ —É–∫–∞–∑–∞–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
        if self.config.csv_files is None:
            self.config.csv_files = [
                'current_1.csv'
            ]
        
        self.is_running = False
        self.current_index = 0
        self.data = []
        self.loaded_files_info = []  # üîß –ù–û–í–û–ï: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
        self._load_data()
        
    def _load_data(self):
        try:
            current_dir = os.path.dirname(os.path.abspath(__file__))  
            data_dir = os.path.join(current_dir, 'data') 
            
            print(f"üîç Looking for CSV files in: {os.path.abspath(data_dir)}")
            print(f"üìã Files to load: {self.config.csv_files}")
            
            # üîß –ù–û–í–û–ï: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Ñ–∞–π–ª –∏–∑ —Å–ø–∏—Å–∫–∞
            found_files = []
            missing_files = []
            
            for filename in self.config.csv_files:
                file_path = os.path.join(data_dir, filename)
                if os.path.exists(file_path):
                    found_files.append((filename, file_path))
                    print(f"  ‚úÖ {filename} - found")
                else:
                    missing_files.append(filename)
                    print(f"  ‚ùå {filename} - not found")
            
            # üîß –ù–û–í–û–ï: –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ–∏—Å–∫–∞
            print(f"\nüìä Search results:")
            print(f"  Found: {len(found_files)} files")
            print(f"  Missing: {len(missing_files)} files")
            
            if missing_files:
                print(f"  Missing files: {', '.join(missing_files)}")
            
            # üîß –ù–û–í–û–ï: –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–∞–∑–Ω—ã–µ —Å—Ü–µ–Ω–∞—Ä–∏–∏
            combined_data = []
            
            if len(found_files) == 0:
                print(f"‚ö†Ô∏è  No CSV files found! Using fallback synthetic data...")
                self._generate_fallback_data()
                return
            
            elif len(found_files) == 1:
                print(f"üìÇ Loading data from single file: {found_files[0][0]}")
            
            else:
                print(f"üìÇ Loading data from {len(found_files)} files...")
            
            # üîß –ù–û–í–û–ï: –ó–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
            for filename, file_path in found_files:
                try:
                    df = pd.read_csv(file_path)
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
                    required_cols = ['current_R', 'current_S', 'current_T']
                    missing_cols = [col for col in required_cols if col not in df.columns]
                    
                    if missing_cols:
                        print(f"    ‚ö†Ô∏è  {filename}: missing columns {missing_cols}, skipping...")
                        continue
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞
                    file_data = []
                    for _, row in df.iterrows():
                        file_data.append({
                            'current_R': float(row['current_R']),
                            'current_S': float(row['current_S']),
                            'current_T': float(row['current_T'])
                        })
                    
                    combined_data.extend(file_data)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ñ–∞–π–ª–µ
                    self.loaded_files_info.append({
                        'filename': filename,
                        'samples': len(file_data),
                        'duration_sec': len(file_data) / self.config.sampling_rate
                    })
                    
                    print(f"    üìä {filename}: {len(file_data)} samples ({len(file_data) / self.config.sampling_rate:.2f} sec)")
                    
                except Exception as e:
                    print(f"    ‚ùå Error loading {filename}: {e}")
            
            # üîß –ù–û–í–û–ï: –§–∏–Ω–∞–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
            if combined_data:
                self.data = combined_data
                total_duration = len(self.data) / self.config.sampling_rate
                print(f"\nüéØ TOTAL LOADED:")
                print(f"  Files: {len(self.loaded_files_info)}")
                print(f"  Samples: {len(self.data)}")
                print(f"  Duration: {total_duration:.2f} seconds")
                print(f"  Data quality: High (Real CSV data)")
            else:
                print(f"‚ùå No valid data loaded from any files!")
                self._generate_fallback_data()
                
        except Exception as e:
            print(f"ERROR in _load_data: {e}")
            print(f"Current working directory: {os.getcwd()}")
            print(f"Generator file location: {os.path.dirname(os.path.abspath(__file__))}")
            self._generate_fallback_data()
    
    def _generate_fallback_data(self):
        """üîß –ù–û–í–û–ï: –°–æ–∑–¥–∞–µ—Ç —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –∫–∞–∫ fallback"""
        import numpy as np
        
        print(f"üîÑ Generating fallback synthetic data...")
        self.data = []
        for i in range(10000):
            t = i / self.config.sampling_rate
            self.data.append({
                'current_R': 3.0 * np.sin(2 * np.pi * 50 * t),
                'current_S': 3.0 * np.sin(2 * np.pi * 50 * t + 2*np.pi/3),
                'current_T': 3.0 * np.sin(2 * np.pi * 50 * t + 4*np.pi/3)
            })
        
        self.loaded_files_info = [{
            'filename': 'synthetic_fallback',
            'samples': len(self.data),
            'duration_sec': len(self.data) / self.config.sampling_rate
        }]
        
        print(f"üîÑ Generated {len(self.data)} synthetic samples ({len(self.data) / self.config.sampling_rate:.2f} sec)")
    
    def set_csv_files(self, filenames: List[str]):
        """üîß –ù–û–í–û–ï: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ CSV —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏"""
        self.config.csv_files = filenames
        self.loaded_files_info = []
        print(f"üìã CSV files list updated: {filenames}")
        self._load_data()
    
    def add_csv_file(self, filename: str):
        """üîß –ù–û–í–û–ï: –î–æ–±–∞–≤–ª—è–µ—Ç —Ñ–∞–π–ª –∫ —Å–ø–∏—Å–∫—É –∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ"""
        if filename not in self.config.csv_files:
            self.config.csv_files.append(filename)
            print(f"‚ûï Added {filename} to files list")
            self._load_data()
        else:
            print(f"‚ö†Ô∏è  File {filename} already in list")
    
    def remove_csv_file(self, filename: str):
        """üîß –ù–û–í–û–ï: –£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª –∏–∑ —Å–ø–∏—Å–∫–∞ –∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ"""
        if filename in self.config.csv_files:
            self.config.csv_files.remove(filename)
            print(f"‚ûñ Removed {filename} from files list")
            self._load_data()
        else:
            print(f"‚ö†Ô∏è  File {filename} not in list")
    
    def get_files_info(self) -> Dict:
        """üîß –ù–û–í–û–ï: –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö"""
        return {
            'configured_files': self.config.csv_files,
            'loaded_files': self.loaded_files_info,
            'total_samples': len(self.data),
            'total_duration_sec': len(self.data) / self.config.sampling_rate if self.data else 0
        }
    
    def generate_sample(self) -> Dict[str, float]:
        if not self.data:
            return {'current_R': 0.0, 'current_S': 0.0, 'current_T': 0.0, 'timestamp': 0.0}
        
        sample = self.data[self.current_index].copy()
        sample['timestamp'] = self.current_index / self.config.sampling_rate
        
        self.current_index = (self.current_index + 1) % len(self.data)
        
        return {
            'current_R': round(sample['current_R'], 8),
            'current_S': round(sample['current_S'], 8),
            'current_T': round(sample['current_T'], 8),
            'timestamp': round(sample['timestamp'], 8)
        }
    
    async def generate_realtime(self) -> List[Dict[str, float]]:
        if not self.is_running:
            return []
            
        batch = []
        for _ in range(self.config.output_batch_size):
            batch.append(self.generate_sample())
            
        await asyncio.sleep(self.config.output_batch_size / self.config.sampling_rate)
        return batch
    
    def start(self):
        self.is_running = True
        self.current_index = 0
        files_count = len(self.loaded_files_info)
        print(f"üöÄ CSV data generator started with {len(self.data)} samples from {files_count} file(s)")
    
    def stop(self):
        self.is_running = False
        print("üõë CSV data generator stopped")
    
    def update_config(self, **kwargs):
        for key, value in kwargs.items():
            if hasattr(self.config, key):
                setattr(self.config, key, value)
                print(f"üîß Config updated: {key} = {value}")
                
                # –ï—Å–ª–∏ –æ–±–Ω–æ–≤–∏–ª–∏ —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤, –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º
                if key == 'csv_files':
                    self._load_data()
    
    def get_quality_metrics(self) -> Dict[str, float]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –¥–ª—è CSV –¥–∞–Ω–Ω—ã—Ö"""
        return {
            "expected_thd_percent": 2.5,
            "noise_contribution": self.config.noise_level * 100,
            "anomaly_contribution": 0.0,
            "quality_score": 95.0,
            "data_source_quality": "High (Real CSV data)",
            "temporal_consistency": 100.0,
            "files_loaded": len(self.loaded_files_info)
        }
